{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9WLGwHyK1/O7DjpQh7wDs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQFNSS6JoxRY",
        "outputId": "a57a1e72-8480-421e-8c3d-2f07954067ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1, Loss: 0.1443, Train Accuracy: 95.60, Test Accuracy: 95.05\n",
            "Epoch 2, Loss: 0.0953, Train Accuracy: 96.99, Test Accuracy: 96.34\n",
            "Epoch 3, Loss: 0.0914, Train Accuracy: 97.00, Test Accuracy: 95.79\n",
            "Epoch 4, Loss: 0.0639, Train Accuracy: 97.96, Test Accuracy: 96.63\n",
            "Epoch 5, Loss: 0.0584, Train Accuracy: 98.10, Test Accuracy: 96.91\n",
            "Epoch 6, Loss: 0.0495, Train Accuracy: 98.35, Test Accuracy: 97.11\n",
            "Epoch 7, Loss: 0.0452, Train Accuracy: 98.54, Test Accuracy: 97.15\n",
            "Epoch 8, Loss: 0.0516, Train Accuracy: 98.34, Test Accuracy: 96.85\n",
            "Epoch 9, Loss: 0.0679, Train Accuracy: 97.78, Test Accuracy: 96.27\n",
            "Epoch 10, Loss: 0.0393, Train Accuracy: 98.71, Test Accuracy: 97.00\n",
            "Epoch 11, Loss: 0.0391, Train Accuracy: 98.74, Test Accuracy: 97.17\n",
            "Epoch 12, Loss: 0.0405, Train Accuracy: 98.64, Test Accuracy: 97.15\n",
            "Epoch 13, Loss: 0.0293, Train Accuracy: 99.05, Test Accuracy: 97.30\n",
            "Epoch 14, Loss: 0.0336, Train Accuracy: 98.88, Test Accuracy: 97.15\n",
            "Epoch 15, Loss: 0.0296, Train Accuracy: 99.00, Test Accuracy: 97.25\n",
            "Epoch 16, Loss: 0.0251, Train Accuracy: 99.16, Test Accuracy: 97.16\n",
            "Epoch 17, Loss: 0.0339, Train Accuracy: 98.89, Test Accuracy: 96.93\n",
            "Epoch 18, Loss: 0.0284, Train Accuracy: 99.00, Test Accuracy: 97.00\n",
            "Epoch 19, Loss: 0.0255, Train Accuracy: 99.18, Test Accuracy: 97.43\n",
            "Epoch 20, Loss: 0.0240, Train Accuracy: 99.19, Test Accuracy: 97.29\n",
            "Final Train Accuracy: 99.19\n",
            "Final Test Accuracy: 97.29\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()  # Disable eager execution to use TensorFlow's graph execution\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train.reshape(-1, 784) / 255.0, x_test.reshape(-1, 784) / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = np.eye(10)[y_train]\n",
        "y_test = np.eye(10)[y_test]\n",
        "\n",
        "# Define model hyperparameters\n",
        "input_size = 784\n",
        "hidden1_size = 128\n",
        "hidden2_size = 64\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "batch_size = 100\n",
        "epochs = 20\n",
        "\n",
        "# Define placeholders for input and output\n",
        "X = tf.compat.v1.placeholder(tf.float32, [None, input_size])\n",
        "y = tf.compat.v1.placeholder(tf.float32, [None, output_size])\n",
        "\n",
        "# Initialize weights and biases\n",
        "weights = {\n",
        "    'w1': tf.Variable(tf.random.truncated_normal([input_size, hidden1_size], stddev=0.1)),\n",
        "    'w2': tf.Variable(tf.random.truncated_normal([hidden1_size, hidden2_size], stddev=0.1)),\n",
        "    'w3': tf.Variable(tf.random.truncated_normal([hidden2_size, output_size], stddev=0.1))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.zeros([hidden1_size])),\n",
        "    'b2': tf.Variable(tf.zeros([hidden2_size])),\n",
        "    'b3': tf.Variable(tf.zeros([output_size]))\n",
        "}\n",
        "\n",
        "# Define feed-forward neural network\n",
        "def neural_network(X):\n",
        "    layer1 = tf.nn.sigmoid(tf.matmul(X, weights['w1']) + biases['b1'])\n",
        "    layer2 = tf.nn.sigmoid(tf.matmul(layer1, weights['w2']) + biases['b2'])\n",
        "    output_layer = tf.matmul(layer2, weights['w3']) + biases['b3']\n",
        "    return output_layer\n",
        "\n",
        "# Compute logits\n",
        "logits = neural_network(X)\n",
        "\n",
        "# Define loss function (cross-entropy)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "# Define accuracy metric\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Run session\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(x_train), batch_size):\n",
        "            batch_x, batch_y = x_train[i:i+batch_size], y_train[i:i+batch_size]\n",
        "            sess.run(optimizer, feed_dict={X: batch_x, y: batch_y})\n",
        "\n",
        "        # Calculate and display loss and accuracy at each epoch\n",
        "        train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: x_train, y: y_train})\n",
        "        test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})\n",
        "        print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Accuracy: {train_acc*100:.2f}, Test Accuracy: {test_acc*100:.2f}\")\n",
        "\n",
        "    # Compute final train and test accuracy\n",
        "    final_train_acc = sess.run(accuracy, feed_dict={X: x_train, y: y_train})\n",
        "    final_test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})\n",
        "    print(f\"Final Train Accuracy: {final_train_acc*100:.2f}\")\n",
        "    print(f\"Final Test Accuracy: {final_test_acc*100:.2f}\")\n",
        "\n",
        "    print(\"Training Complete!\")"
      ]
    }
  ]
}